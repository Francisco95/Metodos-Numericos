{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catedra 08\n",
    "\n",
    "## Modelamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos N puntos $(x_i, y_i)_{i=1\\ldots n}$ que tienen un error de medicion asociado (experimento)\n",
    "\n",
    "Objetivo: Encontrar una forma funcional que modele la dependencia entre $x$ e $y$.\n",
    "\n",
    "$$\n",
    "y(x) = y(x; a_1, a_2,\\ldots, a_n)\n",
    "$$\n",
    "\n",
    "Donde $a_j$ son parametros del modelo.\n",
    "\n",
    "Ademas de encontrar $\\vec{a}_{\\text{optimo}}$, queremos:\n",
    "- Estimacion de la incertidumbre en $\\vec{a}_{\\text{opt}}$.\n",
    "- Medida cuantitativa de la calidad del ajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimador de maxima verosimilitud (MLE)\n",
    "\n",
    "### Idea: Dado un set de parametros $\\vec{a}^*$ cual es la probabilidad de observar lo observado? Cual es el set de $\\vec{a}_{\\text{optimo}}$ que maximiza esa probabilidad?\n",
    "\n",
    "No se puede en general. Asumiremos:\n",
    "1. La relacion es: $$y = y(x) + \\epsilon$$ La relacion admite ruido $$\\epsilon \\leadsto N(0, \\sigma^2)$$\n",
    "   Entonces podemos calcular la probabilidad de observar $[y_i, y_i + dy]$\n",
    "   $$P(y_i) \\propto exp\\left[-\\frac{(y_i-y(x_i;\\vec{a}))^2}{2\\sigma^2}\\right]$$\n",
    "2. Las observaciones son independientes $$P\\left(\\left\\{x_i, y_i\\right\\}_{i=1,\\ldots ,N}\\right) \\propto \\prod_{i=1}^N exp\\left[-\\frac{y_i-y(x_i; \\vec{a}))^2}{2\\sigma^2}\\right]dy$$\n",
    "   Maximizar $P \\Leftrightarrow \\text{minimizar} -\\log(P)$\n",
    "   $$-\\text{ln}\\left(P\\left(\\left\\{x_i, y_i\\right\\}_{i=1,\\ldots,N}\\right)\\right) \\propto \\sum_{i=1}^N \\frac{\\left[y_i - y(x_i; \\vec{a})\\right]^2}{2\\sigma^2}$$\n",
    "   $\\implies$ equivale a minimizar $\\chi^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando $\\sigma = $ const $\\rightarrow$ homocedasticidad, si $\\sigma \\neq$ const $\\rightarrow$ heterocedasticidad\n",
    "$$\\chi^2 = \\sum_{i=1}^N \\frac{\\left[y_i - y(x_i; \\vec{a})\\right]^2}{2\\sigma_i^2} $$\n",
    "$$\\left(\\frac{y_i-y(x_i; \\vec{a})}{2\\sigma_i}\\right) \\leadsto N(0,1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada $i$, el argumento de la sumatoria es $r\\leadsto N(0,1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por definicion la suma de $N$ variables aleatorias $r \\leadsto N(0,1)$ se distribuye como $\\chi^2_N$\n",
    "\n",
    "Cuando hayamos fijado $a_{1,\\ldots, N}$, los terminos en la sumatoria ya no son todos independientes, quedan atados por las M ecuacinoes de la minimizacion de $\\chi^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\implies$ Nos quedan $N-M$ grados de libertad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar la calidad del ajuste $$Q = P(> \\chi^2)$$\n",
    "\n",
    "Que pasa si los errores $\\epsilon$, no son gaussianos?\n",
    "\n",
    "1. Opcion: Si sabemos algo sobre los errores $\\implies$ Monte Carlo\n",
    "   - Parametros del mejor ajuste $\\vec{a}_0$ ($\\neq \\vec{a}_{\\text{verdadero}}$)\n",
    "\n",
    "   Podemos generar un set de datos sintetico: $$y'_i = y(x_i; \\vec{a}_0) + r$$\n",
    "   En donde $r$ es una variable aleatoria que entendemos\n",
    "   - A partir del set sintetico, repito minimizacion de $\\chi^2$, obtengo $\\vec{a}_j$\n",
    "   - Repetir $L$ veces $\\implies \\vec{a}_{1,\\ldots,L}$ $\\implies$ La distribucion de $\\left\\{\\vec{a}_0 - \\vec{a}_j\\right\\}_{j=1,\\ldots,L}$ nos dice cual es la distribucion de $\\vec{a} \\implies$ intervalo de confianza\n",
    "2. Opcion: No sabemos nada sobre los errores de medicion.\n",
    "   La muestra en si misma contiene info sobre el ruido.\n",
    "   La idea es explotarla $\\implies$ __BOOTSTRAP__\n",
    "   - __BOOTSRAP__: Dada una muestra con $N$ mediciones, generamos $L$ sets sinteticos seleccionando __*aleatoriamente*__ y con peso uniforme, $N$ valores de la muestra (se pueden repetir)\n",
    "     Luego sigue igual que MC (Monte Carlo).\n",
    "   Los teoremas de bootsrap demuestran que $\\left\\{\\vec{a}_0 - a_j\\right\\}_{j=1,\\ldots,L} \\rightarrow$ se distribuye como la distancia real.\n",
    "\n",
    "### Dificultad: Para $N$ valores en la muestra $\\implies 10^N$ sets sinteticos posibles.\n",
    "\n",
    "Teoria Asimptotica muestra que $L = N(\\text{ln}N)^2$ genera una \"buena\" aproximacion."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
